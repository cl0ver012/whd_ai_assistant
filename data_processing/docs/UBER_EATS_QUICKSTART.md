# Uber Eats Promos - Quick Start Guide

Get your Uber Eats promotional and sales data into Supabase in 3 easy steps!

## ğŸš€ Quick Start (3 Steps)

### Step 1: Create Database Tables

Open Supabase SQL Editor and run:

```sql
-- Copy and paste the entire contents of:
-- data_processing/sql/setup_uber_eats_promos.sql
```

Or use command line (if you have psql):

```bash
psql -h your-project.supabase.co -U postgres -d postgres -f data_processing/sql/setup_uber_eats_promos.sql
```

This creates:
- âœ… `uber_eats_offers` table (promotional offers)
- âœ… `uber_eats_sales` table (sales by store)

### Step 2: Verify Environment

Make sure your `.env` file has:

```env
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-service-role-key-here
```

### Step 3: Run the Script

```bash
python data_processing/scripts/process_uber_eats_promos.py
```

That's it! ğŸ‰

## ğŸ“Š What Gets Processed

The script automatically finds and processes:

1. **Offers Files**: `*Offers*.csv` (65 rows detected)
   - Promotional campaigns
   - Discount types
   - Target customers
   - Included items

2. **Sales Files**: `*Sales*.csv` (121,022 rows detected)
   - Daily sales by store
   - Channel information
   - Sales amounts
   - Date/time data

## âš¡ Performance

- **Speed**: ~500-1,000 records/second
- **Batch Processing**: 100 rows at a time
- **Safe to Re-run**: Automatically skips duplicates
- **No Data Loss**: All CSV columns preserved

## ğŸ” Quick Query Examples

### View Latest Offers

```sql
SELECT offer, promo_start_date, promo_end_date, items
FROM uber_eats_offers
ORDER BY promo_start_date DESC
LIMIT 10;
```

### Top 10 Stores by Revenue

```sql
SELECT store_name, SUM(total_sales) as revenue
FROM uber_eats_sales
GROUP BY store_name
ORDER BY revenue DESC
LIMIT 10;
```

### Monthly Sales Summary

```sql
SELECT month_name, year, SUM(total_sales) as total
FROM uber_eats_sales
GROUP BY year, month, month_name
ORDER BY year DESC, month DESC;
```

## ğŸ¯ Features

âœ… **Zero Data Loss** - All CSV columns preserved  
âœ… **Fast Processing** - Batch inserts, no delays  
âœ… **Duplicate Safe** - Run multiple times safely  
âœ… **Two Data Types** - Handles offers + sales  
âœ… **Smart Date Parsing** - Multiple formats supported  
âœ… **Progress Tracking** - Real-time feedback  

## ğŸ”„ Re-running the Script

### Normal Mode (Recommended)
Skips existing records - safe to run anytime:

```bash
python data_processing/scripts/process_uber_eats_promos.py
```

### Clear Mode (Fresh Start)
Deletes all existing data first (faster):

```bash
python data_processing/scripts/process_uber_eats_promos.py --clear
```

âš ï¸ Clear mode requires confirmation!

## ğŸ“ Files Location

```
data_processing/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ process_uber_eats_promos.py    â† Run this
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ setup_uber_eats_promos.sql     â† Run this first
â””â”€â”€ docs/
    â”œâ”€â”€ UBER_EATS_QUICKSTART.md        â† You are here
    â””â”€â”€ UBER_EATS_SETUP_GUIDE.md       â† Full documentation

NBX/
â””â”€â”€ Uber Eats Promos/
    â”œâ”€â”€ UberEats Offers - 12 Months.csv
    â””â”€â”€ UberEats Sales - Export.csv
```

## â“ Troubleshooting

### "Missing environment variables"
- Check `.env` file exists in project root
- Verify `SUPABASE_URL` and `SUPABASE_KEY` are set

### "Table does not exist"
- Run the SQL setup file first (Step 1)

### "Data folder not found"
- Ensure `NBX/Uber Eats Promos/` folder exists
- Check CSV files are in the folder

## ğŸ“š More Information

For detailed documentation, see:
- **Full Setup Guide**: `data_processing/docs/UBER_EATS_SETUP_GUIDE.md`
- **Implementation Details**: `data_processing/docs/UBER_EATS_IMPLEMENTATION_SUMMARY.md`

## âœ… Expected Output

When successful, you'll see:

```
======================================================================
PROCESSING COMPLETE
======================================================================
Total records processed: 121,087
Successfully stored: 121,087
Failed: 0
Skipped (already exist): 0
Time elapsed: 120.45 seconds
Speed: 1005.2 records/second

âœ¨ ALL PROPERTIES PRESERVED:
  âœ“ All CSV columns stored as individual database columns
  âœ“ No JSONB - direct column access
  âœ“ No embeddings - simple and fast
  âœ“ Batch processing for maximum speed
  âœ“ Safe to re-run - skips existing records
```

## ğŸ‰ Done!

Your Uber Eats data is now in Supabase and ready for analysis!

**Next steps**:
1. Query your data in Supabase
2. Build dashboards
3. Run analytics
4. Re-run script when you have new data

---

Need help? Check the full documentation in `UBER_EATS_SETUP_GUIDE.md`

